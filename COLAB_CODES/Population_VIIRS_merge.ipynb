{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOllNmhm/u9/r5oFnxBkoIW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepti-Shringare/Downscaling_of_no2map_XGBoost/blob/main/COLAB_CODES/Population_VIIRS_merge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx0aZAu-cojc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =========================\n",
        "# 1. Load datasets\n",
        "# =========================\n",
        "# Corrected the file path to use the previously generated 'GSmerged_SoniaVihar_2024.csv'\n",
        "no2_path = r\"/content/drive/MyDrive/MAJOR_PROJECT/Groundtruth_Satellite/GSmerged_Major_Dhyand_2024.csv\"\n",
        "pop_path = r\"/content/drive/MyDrive/MAJOR_PROJECT/Population_Density/MAJOR_DHYAND_CHAND_NATIONAL_STADIUM_Population_Density.csv\"\n",
        "\n",
        "no2_df = pd.read_csv(no2_path)\n",
        "pop_df = pd.read_csv(pop_path)\n",
        "\n",
        "# =========================\n",
        "# 2. Clean columns\n",
        "# =========================\n",
        "pop_df = pop_df.rename(columns={\n",
        "    'latitude': 'lat',\n",
        "    'longitude': 'lon'\n",
        "})\n",
        "\n",
        "pop_df = pop_df[['station', 'population_density']]\n",
        "\n",
        "# =========================\n",
        "# 3. Merge\n",
        "# =========================\n",
        "final_df = no2_df.merge(pop_df, on='station', how='left')\n",
        "\n",
        "# =========================\n",
        "# 4. Save output\n",
        "# =========================\n",
        "output_path = '/content/drive/MyDrive/MAJOR_PROJECT/GS_Population/MAJOR_DHYAND_CHAND_NATIONAL_STADIUM_2024_NO2_with_population.csv'\n",
        "final_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"✅ Final merged file saved at:\")\n",
        "print(output_path)\n",
        "print(final_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =========================\n",
        "# 1. Load datasets\n",
        "# =========================\n",
        "no2_path = \"/content/drive/MyDrive/MAJOR_PROJECT/GS_Population/NSIT_2024_NO2_with_population.csv\"\n",
        "night_path = \"/content/drive/MyDrive/MAJOR_PROJECT/NightLights/NSIT_VIIRS_NightLights_2024.csv\"\n",
        "\n",
        "no2_df = pd.read_csv(no2_path)\n",
        "night_df = pd.read_csv(night_path)\n",
        "\n",
        "# =========================\n",
        "# 2. Clean & normalize\n",
        "# =========================\n",
        "no2_df['station'] = no2_df['station'].str.strip().str.upper()\n",
        "night_df['station'] = night_df['station'].str.strip().str.upper()\n",
        "\n",
        "# Convert date → datetime\n",
        "no2_df['date'] = pd.to_datetime(no2_df['date'])\n",
        "\n",
        "# Extract month & year from NO2 data\n",
        "no2_df['month'] = no2_df['date'].dt.month\n",
        "no2_df['year'] = no2_df['date'].dt.year\n",
        "\n",
        "# Keep required columns from night lights\n",
        "night_df = night_df[['station', 'month', 'year', 'night_light']]\n",
        "\n",
        "# =========================\n",
        "# 3. Merge (CORRECT WAY)\n",
        "# =========================\n",
        "final_df = no2_df.merge(\n",
        "    night_df,\n",
        "    on=['station', 'month', 'year'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 4. Save output\n",
        "# =========================\n",
        "output_path = \"/content/drive/MyDrive/MAJOR_PROJECT/NSIT_2024_NO2_with_population_nightlights.csv\"\n",
        "final_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"✅ Final merged file saved at:\")\n",
        "print(output_path)\n",
        "print(final_df.head())\n"
      ],
      "metadata": {
        "id": "nK7cGOTARZV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #worked\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =========================\n",
        "# 1. Load datasets\n",
        "# =========================\n",
        "no2_path = \"/content/drive/MyDrive/MAJOR_PROJECT/GS_Population/MAJOR_DHYAND_CHAND_NATIONAL_STADIUM_2024_NO2_with_population.csv\"\n",
        "night_path = \"/content/drive/MyDrive/MAJOR_PROJECT/NightLights/MAJOR_DHYAND_CHAND_NATIONAL_STADIUM_VIIRS_NightLights_2024.csv\"\n",
        "\n",
        "no2_df = pd.read_csv(no2_path)\n",
        "night_df = pd.read_csv(night_path)\n",
        "\n",
        "# =========================\n",
        "# 2. Clean & normalize\n",
        "# =========================\n",
        "no2_df['station'] = no2_df['station'].str.strip().str.upper()\n",
        "night_df['station'] = night_df['station'].str.strip().str.upper()\n",
        "\n",
        "# Convert date → datetime\n",
        "no2_df['date'] = pd.to_datetime(no2_df['date'])\n",
        "\n",
        "# Create merge keys (TEMPORARY)\n",
        "no2_df['month'] = no2_df['date'].dt.month\n",
        "no2_df['year'] = no2_df['date'].dt.year\n",
        "\n",
        "# Keep required columns from night lights\n",
        "night_df = night_df[['station', 'month', 'year', 'night_light']]\n",
        "\n",
        "# =========================\n",
        "# 3. Merge\n",
        "# =========================\n",
        "final_df = no2_df.merge(\n",
        "    night_df,\n",
        "    on=['station', 'month', 'year'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 4. DROP helper columns\n",
        "# =========================\n",
        "final_df = final_df.drop(columns=['month', 'year'])\n",
        "\n",
        "# =========================\n",
        "# 5. Save output\n",
        "# =========================\n",
        "output_path = \"/content/drive/MyDrive/MAJOR_PROJECT/MAJOR_DHYAND_CHAND_NATIONAL_STADIUM_2024_NO2_with_population_nightlights.csv\"\n",
        "final_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"✅ Final merged file saved at:\")\n",
        "print(output_path)\n",
        "print(final_df.head())\n"
      ],
      "metadata": {
        "id": "GnkkTzmcU8Do"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}